{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ipympl as ipl\n",
    "import ipywidgets as widgets\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to my dashboard for my c_964 capstone project. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"A_Z Handwritten Data.csv\").astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.load('history.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('0',axis = 1)\n",
    "y = data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (297960, 28, 28)\n",
      "Test data shape:  (74490, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
    "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
    "\n",
    "print(\"Train data shape: \", train_x.shape)\n",
    "print(\"Test data shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bar graph below shows how many of each letter appear in the data set.\n"
     ]
    }
   ],
   "source": [
    "print(\"The bar graph below shows how many of each letter appear in the data set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4513847cf1a042248f8dde354899067c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_int = np.int0(y)\n",
    "count = np.zeros(26, dtype='int')\n",
    "for i in y_int:\n",
    "    count[i] +=1\n",
    "\n",
    "alphabets = []\n",
    "for i in word_dict.values():\n",
    "    alphabets.append(i)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.barh(alphabets, count)\n",
    "\n",
    "plt.xlabel(\"Number of elements \")\n",
    "plt.ylabel(\"Letter\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cells below contain training data. This is 9 images of hand drawn letters.\n"
     ]
    }
   ],
   "source": [
    "print(\"The cells below contain training data. This is 9 images of hand drawn letters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226f708ccc154178a8d7703ea6ebee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuff = shuffle(train_x[:100])\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    _, shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
    "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of train data:  (297960, 28, 28, 1)\n",
      "New shape of train data:  (74490, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "print(\"New shape of train data: \", train_X.shape)\n",
    "\n",
    "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
    "print(\"New shape of train data: \", test_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of train labels:  (297960, 26)\n",
      "New shape of test labels:  (74490, 26)\n"
     ]
    }
   ],
   "source": [
    "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of train labels: \", train_yOHE.shape)\n",
    "\n",
    "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of test labels: \", test_yOHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "\n",
    "model.add(Dense(26,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "##history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_hand.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##np.save('history.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 137,178\n",
      "Trainable params: 137,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "##model.save(r'model_hand.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are my accuracy measurements. To save on time the training data and history is saved. If you wish to see these change in the live enviroment you will have to go into jupyter notebooks and undo the commented training lines above\n",
      "The validation accuracy is : [0.9799973368644714]\n",
      "The training accuracy is : [0.9795039892196655]\n",
      "The validation loss is : [0.07243233174085617]\n",
      "The training loss is : [0.0743950828909874]\n"
     ]
    }
   ],
   "source": [
    "print(\"These are my accuracy measurements. To save on time the training data and history is saved. If you wish to see these change in the live enviroment you will have to go into jupyter notebooks and undo the commented training lines above\")\n",
    "print(\"The validation accuracy is :\", history['val_accuracy'])\n",
    "print(\"The training accuracy is :\", history['accuracy'])\n",
    "print(\"The validation loss is :\", history['val_loss'])\n",
    "print(\"The training loss is :\", history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are 9 random cells of the testing data. You will see each was compared to its neural network data and a prediction was made.\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are 9 random cells of the testing data. You will see each was compared to its neural network data and a prediction was made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278aac32ecd341e7be044a5b2e1de97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_9():\n",
    "    fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i,ax in enumerate(axes):\n",
    "        img = np.reshape(test_X[i], (28,28))\n",
    "        ax.imshow(img, cmap=\"Greys\")\n",
    "    \n",
    "        pred = word_dict[np.argmax(test_yOHE[i])]\n",
    "        ax.set_title(\"Prediction: \"+pred)\n",
    "        ax.grid()\n",
    "predict_9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "def drawfun():\n",
    "    width = 150  # canvas width\n",
    "    height = 150 # canvas height\n",
    "    center = height//2\n",
    "    white = (255, 255, 255) # canvas back\n",
    "\n",
    "    def save():\n",
    "        # save image to hard drive\n",
    "        filename = \"user_input.jpg\"\n",
    "        output_image.save(filename)\n",
    "\n",
    "        img = cv2.imread(r'user_input.jpg')\n",
    "        img_copy = img.copy()\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (400,440))\n",
    "        img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "        img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "        _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        img_final = cv2.resize(img_thresh, (28,28))\n",
    "        img_final =np.reshape(img_final, (1,28,28,1))\n",
    "        img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
    "\n",
    "        cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))\n",
    "        cv2.imshow('CMS HAND RECOGNITION', img)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    def clear():\n",
    "        master.destroy()\n",
    "        cv2.destroyAllWindows()\n",
    "        drawfun()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        canvas.create_oval(x1, y1, x2, y2, fill=\"black\",width=2)\n",
    "        draw.line([x1, y1, x2, y2],fill=\"black\",width=5)\n",
    "\n",
    "    master = Tk()\n",
    "\n",
    "    # create a tkinter canvas to draw on\n",
    "    canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "    canvas.pack()\n",
    "\n",
    "    # create an empty PIL image and draw object to draw on\n",
    "    output_image = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    canvas.pack(expand=YES, fill=BOTH)\n",
    "    canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "    # add a button to save the image\n",
    "    button=Button(text=\"save\",command=save)\n",
    "    button1=Button(text=\"Try Again\",command=clear)\n",
    "    button.pack()\n",
    "    button1.pack()\n",
    "    master.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My form of interactive queries. Click the button below to bring up a small canvas. click and drag to draw a letter. Click save to see a prediction. you may then click try again to clear the canvas and do another. I would recommend not expanding the canvas, I noticed the larger the canvas the less accurate it got. Probably due to comparing to a 28 x 28 px pictures.\n"
     ]
    }
   ],
   "source": [
    "print(\"My form of interactive queries. Click the button below to bring up a small canvas. click and drag to draw a letter. Click save to see a prediction. you may then click try again to clear the canvas and do another. I would recommend not expanding the canvas, I noticed the larger the canvas the less accurate it got. Probably due to comparing to a 28 x 28 px pictures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09d8b0f943e4fde9cda54a5d49df810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click to draw a sample', layout=Layout(height='50px', width='30%'), style=ButtonStyle(butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "generate_samples_button = widgets.Button(description=\"Click to draw a sample\") \n",
    "\n",
    "generate_samples_button.layout.height='50px'\n",
    "\n",
    "generate_samples_button.layout.width='30%'\n",
    "\n",
    "generate_samples_button.style.button_color=\"lightsalmon\"\n",
    "\n",
    "generate_samples_button.on_click(lambda event: drawfun())\n",
    "\n",
    "display(generate_samples_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A principal component analysi scatter plot. You can see clusters that represent the letters. this allows you to see how similar letters get confused. This is just a random portion of the total data to reduce confusion.\n"
     ]
    }
   ],
   "source": [
    "print(\"A principal component analysi scatter plot. You can see clusters that represent the letters. this allows you to see how similar letters get confused. This is just a random portion of the total data to reduce confusion as the entire dataset was so massive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8875265a4f42b68a98c420a7ed46d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x15ca2291a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    output = widgets.Output()\n",
    "    #l_pca = widgets.Label(value=\"Plotting Principle Component Analysis...\")\n",
    "\n",
    "\n",
    "    \n",
    "    with output:\n",
    "        fig = pyplot.figure()\n",
    "    \n",
    "    p = 0.01\n",
    "    test_data_csv=pd.read_csv(r\"A_Z Handwritten data.csv\", header=0, \n",
    "         skiprows=lambda i: i>0 and random.random() > p)\n",
    "    \n",
    "    label=test_data_csv['0']\n",
    "    drop = test_data_csv.drop('0',axis=1)\n",
    "    \n",
    "    pca_data = drop\n",
    "    \n",
    "    pca= decomposition.PCA()\n",
    "\n",
    "    standard_scaler_data= StandardScaler().fit_transform(pca_data.astype(int))\n",
    "\n",
    "    pca.n_components = 2\n",
    "    fitted_data= pca.fit_transform(standard_scaler_data)\n",
    "\n",
    "\n",
    "    fitted_data=np.vstack((fitted_data.T,label)).T\n",
    "\n",
    "\n",
    "    data_frame = pd.DataFrame(data=fitted_data, columns=(\"1st Principal\", \"2nd Principal\", \"Key\"))\n",
    "\n",
    "    sns.FacetGrid(data_frame, hue='Key',height=6).map(plt.scatter,'1st Principal','2nd Principal').add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
